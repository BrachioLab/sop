{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8902f416-1123-485e-8308-67b2ff4b254e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "[nltk_data] Downloading package punkt to /home/runai-home/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/runai-home/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'imagenet_s',\n",
       "  'root': '/shared_data0/weiqiuy/datasets/imagenet'},\n",
       " 'training': {'batch_size': 16,\n",
       "  'num_epochs': 20,\n",
       "  'mask_batch_size': 64,\n",
       "  'optimizer': {'name': 'adamw', 'lr': 5e-06, 'weight_decay': 0.01}},\n",
       " 'evaluation': {'split': 'val', 'num_data': 1, 'batch_size': 16},\n",
       " 'model': {'type': 'vit',\n",
       "  'base': 'google/vit-base-patch16-224',\n",
       "  'sop': '/shared_data0/weiqiuy/sop/exps/imagenet_lr5e-06_tgtnnz0.2_gg0.0600_gs0.0100_ft_identify_fixk_scratch_ks3/best',\n",
       "  'num_classes': 1000}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../lib/exlib/src')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import sop\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sop.utils.seed_all(42)\n",
    "\n",
    "# config\n",
    "exp_config = sop.ImageNetConfig()\n",
    "val_config = exp_config.get_config('val_sm')\n",
    "val_config['evaluation']['batch_size'] = 16\n",
    "val_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0303f1c9-6a33-4980-96fd-5ba3ca694226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection layer is not frozen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37293/1167232271.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m backbone_model, original_model, processor, backbone_config, model, config = sop.tasks.imagenet.get_model(val_config['model']['type'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                  \u001b[0mbackbone_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                  \u001b[0mbackbone_processor_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                  \u001b[0msop_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                                         )\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../src/sop/tasks/images/imagenet/models.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_type, backbone_model_name, backbone_processor_name, sop_model_name, eval_mode, wrap_proj)\u001b[0m\n\u001b[1;32m     76\u001b[0m                             projection_layer=projection_layer)\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msop_model_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             state_dict = torch.load(os.path.join(sop_model_name, \n\u001b[0m\u001b[1;32m     79\u001b[0m                                             'checkpoint.pth'))\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backbone_model, original_model, processor, backbone_config, model, config = sop.tasks.imagenet.get_model(val_config['model']['type'],\n",
    "                                                                 backbone_model_name=val_config['model']['base'],\n",
    "                                                                 backbone_processor_name=val_config['model']['base'],\n",
    "                                                                 sop_model_name=val_config['model']['sop'], eval_mode=True\n",
    "                                                                                                        )\n",
    "\n",
    "backbone_model = backbone_model.to(device)\n",
    "original_model = original_model.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84021c-cf3e-4f29-a634-6dca7f935a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    'shap_20',\n",
    "    'rise_20',\n",
    "    'lime_20',\n",
    "    'sop',\n",
    "    'fullgrad',\n",
    "    'gradcam',\n",
    "    'intgrad',\n",
    "    'attn',\n",
    "    'archipelago',\n",
    "    'mfaba',\n",
    "    'agi',\n",
    "    'ampe',\n",
    "    'bcos',\n",
    "    'xdnn',\n",
    "    'bagnet',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f2c3f-6d4a-4619-99c8-450001ed2c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sop.metrics import get_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62cc9eb6-bef0-41c5-9972-172230b10a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c521cf25e2416990048c0d2a6ef1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 images and 100 classes\n"
     ]
    }
   ],
   "source": [
    "from sop.tasks.images.imagenet import get_explainer\n",
    "\n",
    "debug = True\n",
    "k = 0.2\n",
    "\n",
    "# method = 'lime_20'\n",
    "# explainer_name = method.split('_')[0]\n",
    "method = 'shap_20'\n",
    "\n",
    "if method == 'sop':\n",
    "    explainer = model\n",
    "else:\n",
    "    explainer = get_explainer(original_model, backbone_model, method.split('_')[0], device)\n",
    "    \n",
    "method_list = method.split('_')\n",
    "explainer_name = method_list[0]\n",
    "\n",
    "if len(method_list) == 2:\n",
    "    suffix = f'_{method_list[1]}'\n",
    "else:\n",
    "    suffix = ''\n",
    "\n",
    "if method != 'sop':\n",
    "    ATTR_VAL_DATA_DIR = f'/shared_data0/weiqiuy/sop/exps/imagenet_vit_1/attributions_seg/{explainer_name}_1_pred{suffix}/val'\n",
    "else:\n",
    "    ATTR_VAL_DATA_DIR = None\n",
    "    \n",
    "val_dataset, val_dataloader = sop.tasks.imagenet.get_dataset(val_config['dataset']['name'], \n",
    "                                          split=val_config['evaluation']['split'], \n",
    "                                          num_data=val_config['evaluation']['num_data'],\n",
    "                                          batch_size=val_config['evaluation']['batch_size'],\n",
    "                                                        attr_dir=ATTR_VAL_DATA_DIR,\n",
    "                                          processor=processor, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61dcd648-1d27-4f22-9a20-92cee4b2d2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49206dcd843e4bb38da30da67c52d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9708592e55364a9aaea1b3955bee26f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "results_all = {}\n",
    "for k in tqdm(np.linspace(0.1, 1, 10)):\n",
    "    results = get_acc(val_dataloader, explainer, method, device, k=k, eval_all=False)\n",
    "    results_all[k] = results\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b68cae-101f-479e-b518-2df8f66993bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_dir = f'/shared_data0/weiqiuy/sop/results/sparsity/{val_config[\"dataset\"][\"name\"]}/'\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# results_path = f'{save_dir}/{method}.pt'\n",
    "\n",
    "# torch.save(results, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7ed56-414d-42bc-bc27-f275d3129a07",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a207f05c-d106-477f-adf9-2d550fa98419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    'shap_20',\n",
    "    'rise_20',\n",
    "    'lime_20',\n",
    "    'sop',\n",
    "    'fullgrad',\n",
    "    'gradcam',\n",
    "    'intgrad',\n",
    "    'attn',\n",
    "    'archipelago',\n",
    "    'mfaba',\n",
    "    'agi',\n",
    "    'ampe',\n",
    "    'bcos',\n",
    "    'xdnn',\n",
    "    'bagnet',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af355284-edaa-4bd0-ac5e-2b4e9a34d151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37293/616298159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/shared_data0/weiqiuy/sop/results/sparsity/{val_config[\"dataset\"][\"name\"]}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{save_dir}/{method}.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_config' is not defined"
     ]
    }
   ],
   "source": [
    "results_all = {}\n",
    "for method in methods:\n",
    "    save_dir = f'/shared_data0/weiqiuy/sop/results/sparsity/{val_config[\"dataset\"][\"name\"]}/'\n",
    "    results_path = f'{save_dir}/{method}.pt'\n",
    "    results = torch.load(results_path)\n",
    "    results_all[method] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab330bf-b864-45d7-835f-c4d8ce4d3c16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'shap_20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37293/3574791993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'shap_20'"
     ]
    }
   ],
   "source": [
    "results_all[method].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4f5cb5-f81c-45f1-85c1-f5c707be6c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['shap_20', 'rise_20', 'lime_20', 'sop', 'fullgrad', 'gradcam', 'intgrad', 'attn', 'archipelago', 'mfaba', 'agi', 'ampe', 'bcos', 'xdnn', 'bagnet'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6429740d-23f0-43a6-ae8a-ed01836758d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37293/95736529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Data provided by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresults_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_mapping\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# X-axis for the plot (assuming these are the points of interest or epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37293/95736529.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Data provided by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresults_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_mapping\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# X-axis for the plot (assuming these are the points of interest or epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Acc plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    # 'font.family': [] #'Times New Roman'\n",
    "})  # Set a default font size\n",
    "\n",
    "\n",
    "name_mapping = {\n",
    "    'lime_20': 'LIME-F',\n",
    "    'shap_20': 'SHAP-F',\n",
    "    'intgrad': 'IG-F',\n",
    "    'gradcam': 'GC-F',\n",
    "    'fullgrad': 'FG-F',\n",
    "    'rise_20': 'RISE-F',\n",
    "    'archipelago': 'Archi-F',\n",
    "    'mfaba': 'MFABA-F',\n",
    "    'agi': 'AGI-F',\n",
    "    'ampe': 'AMPE-F',\n",
    "    'bcos': 'BCos-F',\n",
    "    'xdnn': 'XDNN',\n",
    "    'bagnet': 'BagNet',\n",
    "    'attn': 'FRESH',\n",
    "    'sop': 'SOP',\n",
    "}\n",
    "\n",
    "# Data provided by the user\n",
    "data = {key: results_all[key] for key in name_mapping}\n",
    "\n",
    "# X-axis for the plot (assuming these are the points of interest or epochs)\n",
    "# x = list(range(1, 11))\n",
    "x = np.linspace(0.1, 1, 10)\n",
    "\n",
    "colors_all = cm.get_cmap('tab20')  # The second argument specifies how many discrete colors to generate\n",
    "# hatches_all = ['///', '\\\\\\\\\\\\', '---', '++++', 'xxxx', 'oo', 'OO', '...', '**', '\\\\\\\\\\\\...', '']\n",
    "# hatches_all = ['///', '\\\\\\\\\\\\', '---', '++++', 'xxxx', 'oo','...', '**', '']\n",
    "\n",
    "# # # Generate colors from the colormap\n",
    "# colors = [colors_all(i) for i in range(len(name_mapping))]  # tab10.N is 10\n",
    "# 0123 4567 89ab cdef\n",
    "# colors = [\n",
    "#     '#2222bb',\n",
    "#     '#222277',\n",
    "#     '#22bb22',\n",
    "#     '#227722',\n",
    "#     '#223322',\n",
    "#     '#222233',\n",
    "#     '#227777',\n",
    "#     '#33bb22',\n",
    "#     '#bb7722',\n",
    "#     '#bb3322',\n",
    "#     '#bb22bb',\n",
    "#     '#332277',\n",
    "#     '#777777',\n",
    "#     '#333333',\n",
    "#     '#ff0000',\n",
    "# ]\n",
    "colors = [\n",
    "    '#588c7e',\n",
    "    '#babca2',\n",
    "    '#284e66',\n",
    "    '#7f8d8f',\n",
    "    '#467f7d',\n",
    "    '#acbc8a',\n",
    "    '#ddd8ab',\n",
    "    '#654755',\n",
    "    '#925e64',\n",
    "    '#c68c7a',\n",
    "    '#ecd189',\n",
    "    '#f7e4aa',\n",
    "    '#f2b476',\n",
    "    '#f9d49c',\n",
    "    '#ff5b5c'  #'#db6b5c'\n",
    "]\n",
    "\n",
    "# hatches = [hatches_all[i] for i in range(len(name_mapping))]\n",
    "\n",
    "# Assigning different line styles to each line for better differentiation\n",
    "# line_styles = ['--', '-.', ':', (0, (3, 5, 1, 5)), (0, (3, 1, 1, 1, 1, 1)), (0, (5, 10)), (0, (5, 5)), (0, (3, 10, 1, 10)), '-']\n",
    "# line_styles = ['-'] * len(colors)\n",
    "line_styles = [\n",
    "    '--',                   # Dashed line\n",
    "    '-.',                   # Dash-dot line\n",
    "    ':',                    # Dotted line\n",
    "    (0, (5, 10)),           # Long dashed line\n",
    "    (0, (3, 5, 1, 5)),      # Dash-dot-dot line\n",
    "    (0, (5, 5)),            # Densely dashed line\n",
    "    (0, (3, 1, 1, 1)),      # Densely dash-dot line\n",
    "    (0, (3, 10, 1, 10)),    # Loosely dash-dot line\n",
    "    (0, (1, 1)),            # Densely dotted line\n",
    "    (0, (1, 10)),           # Loosely dotted line\n",
    "    (0, (3, 5, 1, 5, 1, 5)),  # Dash-dot-dot-dot line\n",
    "    (0, (5, 1)),            # Densely dashed line (alternative)\n",
    "    (0, (3, 1, 1, 1, 1, 1)),  # Densely dash-dot-dot line\n",
    "    (0, (10, 5)),            # Loosely dashed line (alternative)\n",
    "    '-',                    # Solid line\n",
    "]\n",
    "\n",
    "# Plotting with updated line styles\n",
    "plt.figure(figsize=(2.4, 2))  # Adjusted for better visualization\n",
    "for (key, values), style, color in zip(data.items(), line_styles, colors):\n",
    "    # print(values)\n",
    "    # print(list(range(len(values) - 1, -1, -1)))\n",
    "    # print(list(values.values()))\n",
    "    # print(key)\n",
    "    plt.plot([1 - xi for xi in x], [1 - list(values.values())[i]['acc'] for i in range(len(values))], label=name_mapping[key], linestyle=style, color=color)\n",
    "\n",
    "    # plt.plot(x, [1 - list(values.values())[i] for i in range(len(values) - 1, -1, -1)], label=name_mapping[key], linestyle=style, color=color)\n",
    "\n",
    "plt.title('ImageNet - VisionTransformer')\n",
    "plt.xlabel('Sparsity', fontsize=12)\n",
    "plt.ylabel('Error', fontsize=12)\n",
    "plt.xticks([0,0.2,0.4,0.6,0.8])\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "legend = plt.legend(title=\"Method\", bbox_to_anchor=(1.05, 1), loc='upper left',  ncol=2,\n",
    "                   labelspacing=0.3, handlelength=1.5, handletextpad=0.5, fontsize=9, \n",
    "                   handleheight=0.5, borderpad=0.5, frameon=True, columnspacing=0.8)\n",
    "# legend = ax.legend(\n",
    "#     title=\"Method\", \n",
    "#     bbox_to_anchor=(1.05, 1), \n",
    "#     loc='upper left',\n",
    "#     labelspacing=0.3,  # Vertical spacing between legend items\n",
    "#     handlelength=1,    # Length of the handles (line or marker length)\n",
    "#     handletextpad=0.5, # Padding between handle and text\n",
    "#     borderpad=0.5,     # Padding inside the legend border\n",
    "#     ncol=2,            # Number of columns\n",
    "#     frameon=True, \n",
    "#     fontsize=9, \n",
    "#     columnspacing=1  # Adjust this value to increase/decrease column distance\n",
    "# )\n",
    "# plt.legend(title=\"Method\", bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2,\n",
    "#            labelspacing=0.2, handlelength=1, handletextpad=0.5, \n",
    "#            handleheight=0.5, borderpad=0.5)\n",
    "plt.grid(True)\n",
    "plt.savefig('imagenet_figs/acc_sparsity_imagenet.pdf', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e6cbf2-d2ef-4a18-8ad7-c4c872997350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/shared_data0/weiqiuy/sop/results/sparsity/imagenet_s/',\n",
       " '/shared_data0/weiqiuy/sop/results/sparsity/imagenet_s//shap_20.pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir, results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0274a380-d4c7-4fab-8855-d0e3fd3ca0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.load(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "502447a1-d074-42b0-ac34-6da29ed2ac1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5625,\n",
       " 'corrects': [False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640db865-7a2e-42f7-a716-c45568252793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
