{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8902f416-1123-485e-8308-67b2ff4b254e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'imagenet_s',\n",
       "  'root': '/shared_data0/weiqiuy/datasets/imagenet'},\n",
       " 'training': {'batch_size': 16,\n",
       "  'num_epochs': 20,\n",
       "  'mask_batch_size': 64,\n",
       "  'optimizer': {'name': 'adamw', 'lr': 5e-06, 'weight_decay': 0.01}},\n",
       " 'evaluation': {'split': 'val', 'num_data': 1, 'batch_size': 16},\n",
       " 'model': {'type': 'vit',\n",
       "  'base': 'google/vit-base-patch16-224',\n",
       "  'sop': '/shared_data0/weiqiuy/sop/exps/imagenet_lr5e-06_tgtnnz0.2_gg0.0600_gs0.0100_ft_identify_fixk_scratch_ks3/best',\n",
       "  'num_classes': 1000}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../lib/exlib/src')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import sop\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sop.utils.seed_all(42)\n",
    "\n",
    "# config\n",
    "exp_config = sop.ImageNetConfig()\n",
    "val_config = exp_config.get_config('val_sm')\n",
    "val_config['evaluation']['batch_size'] = 16\n",
    "val_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0303f1c9-6a33-4980-96fd-5ba3ca694226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection layer is not frozen\n",
      "projection layer is not frozen\n",
      "Loaded step 40100\n"
     ]
    }
   ],
   "source": [
    "backbone_model, original_model, processor, backbone_config, model, config = sop.tasks.imagenet.get_model(val_config['model']['type'],\n",
    "                                                                 backbone_model_name=val_config['model']['base'],\n",
    "                                                                 backbone_processor_name=val_config['model']['base'],\n",
    "                                                                 sop_model_name=val_config['model']['sop'], eval_mode=True\n",
    "                                                                                                        )\n",
    "\n",
    "backbone_model = backbone_model.to(device)\n",
    "original_model = original_model.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a84021c-cf3e-4f29-a634-6dca7f935a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    'shap_20',\n",
    "    'rise_20',\n",
    "    'lime_20',\n",
    "    'sop',\n",
    "    'fullgrad',\n",
    "    'gradcam',\n",
    "    'intgrad',\n",
    "    'attn',\n",
    "    'archipelago',\n",
    "    'mfaba',\n",
    "    'agi',\n",
    "    'ampe',\n",
    "    'bcos',\n",
    "    'xdnn',\n",
    "    'bagnet',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6f2c3f-6d4a-4619-99c8-450001ed2c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sop.metrics import get_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62cc9eb6-bef0-41c5-9972-172230b10a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c521cf25e2416990048c0d2a6ef1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 images and 100 classes\n"
     ]
    }
   ],
   "source": [
    "from sop.tasks.images.imagenet import get_explainer\n",
    "\n",
    "debug = True\n",
    "k = 0.2\n",
    "\n",
    "# method = 'lime_20'\n",
    "# explainer_name = method.split('_')[0]\n",
    "method = 'shap_20'\n",
    "\n",
    "if method == 'sop':\n",
    "    explainer = model\n",
    "else:\n",
    "    explainer = get_explainer(original_model, backbone_model, method.split('_')[0], device)\n",
    "    \n",
    "method_list = method.split('_')\n",
    "explainer_name = method_list[0]\n",
    "\n",
    "if len(method_list) == 2:\n",
    "    suffix = f'_{method_list[1]}'\n",
    "else:\n",
    "    suffix = ''\n",
    "\n",
    "if method != 'sop':\n",
    "    ATTR_VAL_DATA_DIR = f'/shared_data0/weiqiuy/sop/exps/imagenet_vit_1/attributions_seg/{explainer_name}_1_pred{suffix}/val'\n",
    "else:\n",
    "    ATTR_VAL_DATA_DIR = None\n",
    "    \n",
    "val_dataset, val_dataloader = sop.tasks.imagenet.get_dataset(val_config['dataset']['name'], \n",
    "                                          split=val_config['evaluation']['split'], \n",
    "                                          num_data=val_config['evaluation']['num_data'],\n",
    "                                          batch_size=val_config['evaluation']['batch_size'],\n",
    "                                                        attr_dir=ATTR_VAL_DATA_DIR,\n",
    "                                          processor=processor, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61dcd648-1d27-4f22-9a20-92cee4b2d2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49206dcd843e4bb38da30da67c52d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9708592e55364a9aaea1b3955bee26f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "results_all = {}\n",
    "for k in tqdm(np.linspace(0.1, 1, 10)):\n",
    "    results = get_acc(val_dataloader, explainer, method, device, k=k, eval_all=False)\n",
    "    results_all[k] = results\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b68cae-101f-479e-b518-2df8f66993bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_dir = f'/shared_data0/weiqiuy/sop/results/sparsity/{val_config[\"dataset\"][\"name\"]}/'\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# results_path = f'{save_dir}/{method}.pt'\n",
    "\n",
    "# torch.save(results, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e6cbf2-d2ef-4a18-8ad7-c4c872997350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/shared_data0/weiqiuy/sop/results/sparsity/imagenet_s/',\n",
       " '/shared_data0/weiqiuy/sop/results/sparsity/imagenet_s//shap_20.pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir, results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0274a380-d4c7-4fab-8855-d0e3fd3ca0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.load(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "502447a1-d074-42b0-ac34-6da29ed2ac1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5625,\n",
       " 'corrects': [False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640db865-7a2e-42f7-a716-c45568252793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
