{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06646834-efbd-4e22-944d-b2857dfd67d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a09585-43de-4080-8030-f74fe225e231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'imagenet',\n",
       "  'root': '/shared_data0/weiqiuy/datasets/imagenet'},\n",
       " 'training': {'batch_size': 16,\n",
       "  'num_epochs': 20,\n",
       "  'mask_batch_size': 64,\n",
       "  'optimizer': {'name': 'adamw', 'lr': 5e-06, 'weight_decay': 0.01}},\n",
       " 'evaluation': {'split': 'val', 'num_data': 1, 'batch_size': 2},\n",
       " 'model': {'type': 'vit',\n",
       "  'base': 'google/vit-base-patch16-224',\n",
       "  'sop': '/shared_data0/weiqiuy/sop/exps/imagenet_lr5e-06_tgtnnz0.2_gg0.0600_gs0.0100_ft_identify_fixk_scratch_ks3/best',\n",
       "  'num_classes': 1000}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../lib/exlib/src')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import sop\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sop.utils.seed_all(42)\n",
    "\n",
    "# config\n",
    "exp_config = sop.ImageNetConfig()\n",
    "val_config = exp_config.get_config('val_sm')\n",
    "val_config['evaluation']['batch_size'] = 2\n",
    "val_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f3ad36-6249-42e5-98e1-3df5a519df62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection layer is not frozen\n",
      "projection layer is not frozen\n",
      "Loaded step 40100\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "backbone_model, processor, backbone_config = sop.utils.imagenet_utils.get_model(val_config['model']['type'],\n",
    "                                                                 backbone_model_name=val_config['model']['base'],\n",
    "                                                                 backbone_processor_name=val_config['model']['base'],\n",
    "                                                                )\n",
    "backbone_model = backbone_model.to(device)\n",
    "\n",
    "# get wrapped original model\n",
    "from sop.utils.imagenet_utils import WrappedModel\n",
    "\n",
    "original_model = WrappedModel(backbone_model, output_type='logits')\n",
    "original_model = original_model.to(device)\n",
    "\n",
    "# config\n",
    "from exlib.modules.sop import SOPConfig, get_chained_attr\n",
    "\n",
    "config = SOPConfig(os.path.join(val_config['model']['sop'], 'config.json'))\n",
    "\n",
    "config.group_sel_scale = 0.05\n",
    "\n",
    "config.__dict__.update(backbone_config.__dict__)\n",
    "config.num_labels = len(backbone_config.id2label)\n",
    "\n",
    "# get sop model\n",
    "from sop.utils.imagenet_utils import get_model, get_wrapped_models\n",
    "\n",
    "wrapped_backbone_model, class_weights, projection_layer = get_wrapped_models(\n",
    "    backbone_model,\n",
    "    config\n",
    ")\n",
    "wrapped_backbone_model = wrapped_backbone_model.to(device)\n",
    "class_weights = class_weights.to(device)\n",
    "projection_layer = projection_layer.to(device)\n",
    "\n",
    "# sop\n",
    "from exlib.modules.sop import SOPImageCls4\n",
    "\n",
    "model = SOPImageCls4(config, wrapped_backbone_model, \n",
    "                     class_weights=class_weights, \n",
    "                     projection_layer=projection_layer)\n",
    "state_dict = torch.load(os.path.join(val_config['model']['sop'], \n",
    "                                     'checkpoint.pth'))\n",
    "print('Loaded step', state_dict['step'])\n",
    "model.load_state_dict(state_dict['model'], strict=False)\n",
    "model = model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30fe3686-25a3-400a-9e93-2a0728b70c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 images and 1000 classes\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "val_dataset, val_dataloader = sop.utils.get_dataset(val_config['dataset']['name'], \n",
    "                                          split=val_config['evaluation']['split'], \n",
    "                                          num_data=val_config['evaluation']['num_data'],\n",
    "                                          batch_size=val_config['evaluation']['batch_size'],\n",
    "                                          processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe90cc4-123c-44ea-83a3-e1a626ffcbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sop.metrics import get_all_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e51d96-42de-4745-b1fe-d089f5c8dfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explainer_name = 'lime'\n",
    "# fids = get_all_fidelity(val_dataloader, original_model, backbone_model, explainer_name, val_config['model']['num_classes'], device, skip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0880a279-8570-4484-8b4e-1ac16931ea63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfaba\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8107ae65099642a8b90b0243859812b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(expln) 2\n",
      "agi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31649df6ef294be7b79d3f8aae3715f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fd02d359c1425eaf24053dd1e9303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0cf6e110754ed6a07ad831e8e82eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(expln) 2\n",
      "ampe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c140cbf0db4cc38b0912885e2c806b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(expln) 2\n",
      "bcos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/runai-home/.cache/torch/hub/B-cos_B-cos-v2_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92224fc7aa24c67bb6fed722594aec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(expln) 2\n",
      "xdnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11a696fe7c147e7afc7aee495ce224f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "attributions torch.Size([16, 3, 224, 224])\n",
      "outputs torch.Size([16, 1000])\n",
      "len(expln) 2\n",
      "bagnet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52f051bd9b941899fc15dba02a47691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.15 GiB total capacity; 66.00 GiB already allocated; 16.19 MiB free; 67.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31041/4273959937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     fids = get_all_fidelity(val_dataloader, original_model, backbone_model, explainer_name, \n\u001b[0m\u001b[1;32m     26\u001b[0m                             val_config['model']['num_classes'], device, skip=True)\n\u001b[1;32m     27\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../src/sop/metrics/__init__.py\u001b[0m in \u001b[0;36mget_all_fidelity\u001b[0;34m(dataloader, original_model, backbone_model, explainer_name, num_classes, device, reduction, skip, progress_bar)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         expln, probs = get_expln_all_classes(original_model,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                                \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                num_classes) #val_config['model']['num_classes']\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../src/sop/utils/expln_utils.py\u001b[0m in \u001b[0;36mget_expln_all_classes\u001b[0;34m(original_model, inputs, explainer, num_classes)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mexpln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../lib/exlib/src/exlib/modules/bagnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t, return_groups, mini_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         attrs, preds = get_explanations_in_minibatches(x, t, get_attr_fn, mini_batch_size=mini_batch_size, \n\u001b[0m\u001b[1;32m     62\u001b[0m                         show_pbar=False, model=self.model, patchsize=self.patchsize)\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../lib/exlib/src/exlib/explainers/common.py\u001b[0m in \u001b[0;36mget_explanations_in_minibatches\u001b[0;34m(x, t, get_attr_fn, mini_batch_size, show_pbar, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_expand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_expand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mattrs_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attr_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, C, H, W) same as x_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mattrs_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/metrics/../../lib/exlib/src/exlib/modules/bagnet.py\u001b[0m in \u001b[0;36mget_attr_fn\u001b[0;34m(x, t, model, patchsize)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/github/bag-of-local-features-models/bagnets/pytorchnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/github/bag-of-local-features-models/bagnets/pytorchnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.15 GiB total capacity; 66.00 GiB already allocated; 16.19 MiB free; 67.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "explainer_names = [\n",
    "    # 'lime',\n",
    "    # 'shap',\n",
    "    # 'rise',\n",
    "    # 'intgrad',\n",
    "    # 'gradcam',\n",
    "    # 'archipelago',\n",
    "    # 'fullgrad',\n",
    "    # 'attn', # need to make it an actual model\n",
    "    'mfaba',\n",
    "    'agi',\n",
    "    'ampe',\n",
    "    'bcos',\n",
    "    'xdnn',\n",
    "    'bagnet'\n",
    "]\n",
    "\n",
    "fids_dict = {}\n",
    "\n",
    "for explainer_name in explainer_names:\n",
    "    print(explainer_name)\n",
    "    start = time.time()\n",
    "    fids = get_all_fidelity(val_dataloader, original_model, backbone_model, explainer_name, \n",
    "                            val_config['model']['num_classes'], device, skip=True)\n",
    "    end = time.time()\n",
    "    fids_dict[explainer_name] = {\n",
    "        'fid': fids,\n",
    "        'time': end - start\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44398a0b-5cee-4ea2-80c5-c1b36eaa9f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_path = 'results/fidelity.pt'\n",
    "\n",
    "torch.save(fids_dict, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840aed1-9e59-4381-a004-f026c53a98bc",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603157f-626e-4d6c-b567-3992577f8285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f1994068cb4007a254e27c7b65f390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262020f3b61442f4b112fff27f9ed4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ee84f1e79e418b95abad2c97b665fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need attn and sop\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/shared_data0/weiqiuy/exlib/src')\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# results_dir = '/shared_data0/weiqiuy/sop/results/imagenet_s'\n",
    "results_dir = '/scratch/weiqiuy/sop/fidelity/imagenet_s'\n",
    "num_examples = 50\n",
    "\n",
    "explainer_names = [\n",
    "    'lime',\n",
    "    'shap',\n",
    "    'rise',\n",
    "    'intgrad',\n",
    "    'gradcam',\n",
    "    'archipelago',\n",
    "    'fullgrad',\n",
    "    # 'attn', # need to make it an actual model\n",
    "    'mfaba',\n",
    "    'agi',\n",
    "    'ampe',\n",
    "    'bcos',\n",
    "    'xdnn',\n",
    "    'bagnet'\n",
    "]\n",
    "\n",
    "fids_dict = {}\n",
    "for explainer_name in tqdm(explainer_names):\n",
    "    print(explainer_name)\n",
    "    # break\n",
    "    fids = []\n",
    "    \n",
    "    dirname = os.path.join(results_dir, explainer_name)\n",
    "    for fi in tqdm(range(num_examples)):\n",
    "        # break\n",
    "\n",
    "        data = torch.load(os.path.join(dirname, f'{fi}.pt'))\n",
    "        fids.append(data['fid'])\n",
    "    fids_dict[explainer_name] = torch.stack(fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d609fbb-fa19-493d-8c98-2e33fce8d668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(fids_dict, 'fids_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0483e9-3f18-455e-b2f4-604475239e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['expln', 'probs', 'fid'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b232d9cc-d1b5-4613-9ada-acd7788cf7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2274], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72347237-6fd6-4ac5-8339-969e7917e427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
