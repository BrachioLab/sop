{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8f4d8c-3793-49c8-aa31-9a5eb4722f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sys\n",
    "sys.path.append('../../lib/exlib/src')\n",
    "from exlib.modules.sop import SOPImageCls, SOPConfig, get_chained_attr\n",
    "from exlib.datasets.cosmogrid import CosmogridDataset, CNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5f6158-adfd-4089-ad77-01c862c55223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "SEED = 42\n",
    "if SEED != -1:\n",
    "    # Torch RNG\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Python RNG\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070bd076-9c76-4d9d-827d-144a275ce533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model paths\n",
    "backbone_model_name = '../../data/cosmogrid/CNN_mass_maps.pth'\n",
    "\n",
    "# data paths\n",
    "TRAIN_DATA_DIR = '../../data/cosmogrid'\n",
    "VAL_DATA_DIR = '../../data/cosmogrid'\n",
    "mask_path = '../../data/cosmogrid/masks/X_maps_Cosmogrid_100k_watershed_diagonal.npy'\n",
    "\n",
    "# training args\n",
    "batch_size = 16\n",
    "lr = 0.0005\n",
    "num_epochs = 20\n",
    "warmup_steps = 2000\n",
    "mask_batch_size = 64\n",
    "\n",
    "# experiment args\n",
    "exp_dir = '../../exps/cosmogrid_4h/best'\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "output_dirname = os.path.join(exp_dir, 'val_results')\n",
    "os.makedirs(output_dirname, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e38a1cc-41fa-4dda-a6cd-f01a1a02d096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = SOPConfig(os.path.join(exp_dir, 'config.json'))\n",
    "\n",
    "backbone_model = CNNModel(config.num_labels)\n",
    "state_dict = torch.load(backbone_model_name)\n",
    "backbone_model.load_state_dict(state_dict=state_dict)\n",
    "processor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e4f8e4-acc6-47e0-a2d7-4941bc9a6131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_transform(mask):\n",
    "    seg_mask_cut_off = config.num_masks_max\n",
    "    # Preprocess the mask using the ViTImageProcessor\n",
    "    if len(mask.shape) == 2 and mask.dtype == torch.bool:\n",
    "        mask_dim1, mask_dim2 = mask.shape\n",
    "        mask = mask.unsqueeze(0).expand(3, \n",
    "                                        mask_dim1, \n",
    "                                        mask_dim2).float()\n",
    "        if processor is not None:\n",
    "            inputs = processor(mask, \n",
    "                            do_rescale=False, \n",
    "                            do_normalize=False,\n",
    "                            return_tensors='pt')\n",
    "            # (1, 3, 224, 224)\n",
    "            return inputs['pixel_values'][0][0]\n",
    "        else:\n",
    "            return mask\n",
    "    else: # len(mask.shape) == 3\n",
    "        if mask.dtype != torch.bool:\n",
    "            if len(mask.shape) == 2:\n",
    "                mask = mask.unsqueeze(0)\n",
    "            mask = convert_idx_masks_to_bool(mask)\n",
    "        bsz, mask_dim1, mask_dim2 = mask.shape\n",
    "        mask = mask.unsqueeze(1).expand(bsz, \n",
    "                                        3, \n",
    "                                        mask_dim1, \n",
    "                                        mask_dim2).float()\n",
    "\n",
    "        if bsz < seg_mask_cut_off:\n",
    "            repeat_count = seg_mask_cut_off // bsz + 1\n",
    "            mask = torch.cat([mask] * repeat_count, dim=0)\n",
    "\n",
    "        # add additional mask afterwards\n",
    "        mask_sum = torch.sum(mask[:seg_mask_cut_off - 1], dim=0, keepdim=True).bool()\n",
    "        if False in mask_sum:\n",
    "            mask = mask[:seg_mask_cut_off - 1]\n",
    "            compensation_mask = (1 - mask_sum.int()).bool()\n",
    "            mask = torch.cat([mask, compensation_mask])\n",
    "        else:\n",
    "            mask = mask[:seg_mask_cut_off]\n",
    "\n",
    "        if processor is not None:\n",
    "            inputs = processor(mask, \n",
    "                            do_rescale=False, \n",
    "                            do_normalize=False,\n",
    "                            return_tensors='pt')\n",
    "            \n",
    "            return inputs['pixel_values'][:,0]\n",
    "        else:\n",
    "            return mask[:,0]\n",
    "        \n",
    "def convert_idx_masks_to_bool(masks):\n",
    "    \"\"\"\n",
    "    input: masks (1, img_dim1, img_dim2)\n",
    "    output: masks_bool (num_masks, img_dim1, img_dim2)\n",
    "    \"\"\"\n",
    "    unique_idxs = torch.sort(torch.unique(masks)).values\n",
    "    idxs = unique_idxs.view(-1, 1, 1)\n",
    "    broadcasted_masks = masks.expand(unique_idxs.shape[0], \n",
    "                                     masks.shape[1], \n",
    "                                     masks.shape[2])\n",
    "    masks_bool = (broadcasted_masks == idxs)\n",
    "    return masks_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660fdf44-1533-4387-829f-a044222d033e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples used for training: 80000\n",
      "# samples used for validation: 10000\n",
      "# samples used for testing: 10000\n",
      "# total samples: 100000\n",
      "x shape (80000, 66, 66) (10000, 66, 66) (10000, 66, 66)\n",
      "y shape (80000, 6) (10000, 6) (10000, 6)\n",
      "masks shape (80000, 66, 66) (10000, 66, 66) (10000, 66, 66)\n",
      "-- ALL --\n",
      "max 0.7257571922558966\n",
      "min -0.034935039865926346\n",
      "-- SPLIT train --\n",
      "max 0.7257571922558966\n",
      "min -0.034935039865926346\n",
      "Finished loading 80000 train images ... \n",
      "# samples used for training: 80000\n",
      "# samples used for validation: 10000\n",
      "# samples used for testing: 10000\n",
      "# total samples: 100000\n",
      "x shape (80000, 66, 66) (10000, 66, 66) (10000, 66, 66)\n",
      "y shape (80000, 6) (10000, 6) (10000, 6)\n",
      "masks shape (80000, 66, 66) (10000, 66, 66) (10000, 66, 66)\n",
      "-- ALL --\n",
      "max 0.6323861033355062\n",
      "min -0.031224769235240986\n",
      "-- SPLIT val --\n",
      "max 0.6323861033355062\n",
      "min -0.031224769235240986\n",
      "Finished loading 10000 val images ... \n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_size, val_size = -1, -1\n",
    "# train_size = 100\n",
    "# val_size = 100\n",
    "train_dataset = CosmogridDataset(data_dir=TRAIN_DATA_DIR, split='train', data_size=train_size,\n",
    "                                 mask_path=mask_path, mask_transform=mask_transform)\n",
    "val_dataset = CosmogridDataset(data_dir=TRAIN_DATA_DIR, split='val', data_size=train_size,\n",
    "                                 mask_path=mask_path, mask_transform=mask_transform)\n",
    "\n",
    "# Create a DataLoader to batch and shuffle the data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f491ca40-aca7-4018-b4de-5a51607e6137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep copy class weights\n"
     ]
    }
   ],
   "source": [
    "backbone_model = backbone_model.to(device)\n",
    "class_weights = get_chained_attr(backbone_model, config.finetune_layers[0]).weight #.clone().to(device)\n",
    "class_weights.shape\n",
    "model = SOPImageCls(config, backbone_model) #, class_weights=class_weights, projection_layer=None)\n",
    "model_state_dict = torch.load(os.path.join(exp_dir, 'checkpoint.pth'), map_location=device)['model']\n",
    "model.load_state_dict(model_state_dict)\n",
    "model = model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769189ba-657c-4426-b270-e7daa7439060",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "iter_val_dataloader = iter(val_dataloader)\n",
    "# for _ in tqdm(range(100)):\n",
    "batch = next(iter_val_dataloader)\n",
    "\n",
    "inputs, labels, masks, masks_i = batch\n",
    "inputs = inputs.to(device, dtype=torch.float)\n",
    "labels = labels.to(device, dtype=torch.float)\n",
    "masks = masks.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs, segs=masks, mask_batch_size=mask_batch_size, return_tuple=True)\n",
    "    original_logits = backbone_model(inputs).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7f51f0-c8c6-4e02-9463-a06f7064d3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logits',\n",
       " 'logits_all',\n",
       " 'pooler_outputs_all',\n",
       " 'masks',\n",
       " 'mask_weights',\n",
       " 'attributions',\n",
       " 'attributions_max',\n",
       " 'attributions_all',\n",
       " 'flat_masks',\n",
       " 'grouped_attributions')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb49a81a-717c-41d6-9404-00e7f115d122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 800, 66, 66]),\n",
       " torch.Size([16, 800, 2]),\n",
       " torch.Size([16, 1, 66, 66]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.masks.shape, outputs.mask_weights.shape, outputs.attributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f4f3d3-89d8-4599-991c-1ab3da11a916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "logits_all = outputs.logits_all\n",
    "masks = outputs.masks\n",
    "mask_weights = outputs.mask_weights\n",
    "attributions = outputs.attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffb8b07-0e9c-4016-becf-1bdde93af703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "loss_sop = criterion(logits, labels)\n",
    "loss_original = criterion(original_logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154bcff3-995c-4f9d-82aa-d972d25ac744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bsz, num_masks, num_labels = logits_all.shape\n",
    "\n",
    "losses = criterion(logits_all.reshape(-1, model.config.num_labels), \n",
    "                 labels.unsqueeze(1).expand(bsz, \n",
    "                                            num_masks, \n",
    "                                            num_labels).reshape(-1, num_labels))\n",
    "losses = losses.reshape(logits_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684263e0-cc12-4ef2-b0af-7f789d87368d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "masks_used = masks[i][mask_weights[i].sum(-1).bool()]  # get masks that are used for any class\n",
    "mask_weights_used = mask_weights[i][mask_weights[i].sum(-1).bool()]\n",
    "logits_used = logits_all[i][mask_weights[i].sum(-1).bool()]\n",
    "losses_used = losses[i][mask_weights[i].sum(-1).bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbde9fd8-cd7f-4b69-ab6b-21c378efe317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_masks_used, reverse_indices, counts = torch.unique(masks_used, \n",
    "                                                        dim=0, \n",
    "                                                        return_inverse=True, \n",
    "                                                        return_counts=True)\n",
    "indices = []\n",
    "reverse_indices = reverse_indices.cpu().numpy().tolist()\n",
    "\n",
    "for j in range(len(counts)):\n",
    "    indices.append(reverse_indices.index(j))\n",
    "\n",
    "unique_mask_weights_used = mask_weights_used[indices] * counts.view(-1, 1)\n",
    "unique_logits_used = logits_used[indices]\n",
    "unique_losses_used = losses_used[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9f4440-a682-4673-bd70-ab32bb2014fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entry = {'image': inputs[i],\n",
    "         'original_logits': original_logits[i],\n",
    "        'logits': logits[i],\n",
    "        'unique_logits_used': unique_logits_used,\n",
    "        'masks': masks[i],\n",
    "        'unique_masks_used': unique_masks_used,\n",
    "        'unique_mask_weights_used': unique_mask_weights_used,\n",
    "        'unique_losses_used': unique_losses_used,\n",
    "        'label': labels[i],\n",
    "        'counts': counts,\n",
    "        'num_labels': model.config.num_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceaab5f2-01f6-4a6a-8dd2-59d4d2c45155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[-0.0038, -0.0044, -0.0079,  ...,  0.0032, -0.0029, -0.0011],\n",
       "          [-0.0005, -0.0063, -0.0056,  ...,  0.0062,  0.0031,  0.0016],\n",
       "          [ 0.0036, -0.0004,  0.0004,  ..., -0.0022,  0.0012, -0.0012],\n",
       "          ...,\n",
       "          [ 0.0084,  0.0095,  0.0037,  ..., -0.0075, -0.0046, -0.0057],\n",
       "          [ 0.0031,  0.0061, -0.0007,  ..., -0.0068, -0.0039, -0.0073],\n",
       "          [ 0.0038,  0.0138, -0.0004,  ..., -0.0027, -0.0030, -0.0082]]],\n",
       "        device='cuda:0'),\n",
       " 'original_logits': tensor([0.3602, 0.5460], device='cuda:0'),\n",
       " 'logits': tensor([0.3269, 0.6040], device='cuda:0'),\n",
       " 'unique_logits_used': tensor([[0.3269, 0.6040]], device='cuda:0'),\n",
       " 'masks': tensor([[[0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518],\n",
       "          [0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518],\n",
       "          [0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518],\n",
       "          ...,\n",
       "          [0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518],\n",
       "          [0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518],\n",
       "          [0.6518, 0.6518, 0.6518,  ..., 0.6518, 0.6518, 0.6518]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "        device='cuda:0'),\n",
       " 'unique_masks_used': tensor([[[0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329],\n",
       "          [0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329],\n",
       "          [0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329],\n",
       "          ...,\n",
       "          [0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329],\n",
       "          [0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329],\n",
       "          [0.1329, 0.1329, 0.1329,  ..., 0.1329, 0.1329, 0.1329]]],\n",
       "        device='cuda:0'),\n",
       " 'unique_mask_weights_used': tensor([[1., 1.]], device='cuda:0'),\n",
       " 'unique_losses_used': tensor([[0.0011, 0.0232]], device='cuda:0'),\n",
       " 'label': tensor([0.2934, 0.4518], device='cuda:0'),\n",
       " 'counts': tensor([4], device='cuda:0'),\n",
       " 'num_labels': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa78cfcf-4fed-48c1-9779-ac74b3b4f100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_plotter(image, mask, type='dim'): \n",
    "    default_cmap = matplotlib.rcParams['image.cmap']\n",
    "    cmap = plt.get_cmap(default_cmap)\n",
    "    gray_cmap = plt.get_cmap('gray')\n",
    "    \n",
    "    norm = plt.Normalize()\n",
    "    normed_image = norm(image)\n",
    "    # normed_image = np.clip((image - img_min) / (img_max - img_min) * 3, 0, 1)\n",
    "    rgb_image = cmap(normed_image)\n",
    "    if type == 'dim':\n",
    "        gray_image = (gray_cmap(normed_image) / 2)\n",
    "        mask_bool = np.repeat((mask > 0)[:,:,None], 4, axis=-1)\n",
    "        gray_image[mask_bool] = rgb_image[mask_bool]\n",
    "        plt.imshow(gray_image)\n",
    "    elif type == 'contour':\n",
    "        # 1. Find the contours of the mask\n",
    "        mask_bool = (mask > 0).astype(np.float32)\n",
    "        dilated_mask_bool = binary_dilation(mask_bool)\n",
    "        contours_original = measure.find_contours(mask_bool, 0.5)\n",
    "        contours_dilated = measure.find_contours(dilated_mask_bool, 0.51)\n",
    "\n",
    "        # 2. Overlay the contours on top of the original image\n",
    "        plt.imshow(rgb_image)\n",
    "\n",
    "        for contour in contours_dilated:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='white')  # color can be changed as needed\n",
    "\n",
    "        for contour in contours_original:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='red')  # color can be changed as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc037ca-a038-48bb-a1e6-3b47f2c083d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_weights_for_unique_masks(masks, masks_weights, loss): #, poolers):\n",
    "    # Convert each boolean mask to a unique string of 0s and 1s\n",
    "    mask_strs = [''.join(map(str, mask.bool().int().flatten().tolist())) for mask in masks]\n",
    "    img_size = 66\n",
    "\n",
    "    # Dictionary to store summed weights for each unique mask\n",
    "    unique_masks_weights = {}\n",
    "    unique_masks_loss = {}\n",
    "    unique_masks_count = {}\n",
    "    unique_masks_dict = {}\n",
    "\n",
    "    for i, (mask_str, weight, loss) in enumerate(zip(mask_strs, masks_weights, loss)):\n",
    "        if mask_str in unique_masks_weights:\n",
    "            unique_masks_weights[mask_str] += weight\n",
    "            unique_masks_loss[mask_str] += loss\n",
    "            unique_masks_count[mask_str] += 1\n",
    "        else:\n",
    "            unique_masks_dict[mask_str] = masks[i]\n",
    "            unique_masks_weights[mask_str] = weight\n",
    "            unique_masks_loss[mask_str] = loss\n",
    "            unique_masks_count[mask_str] = 1\n",
    "\n",
    "    # Convert dictionary keys back to boolean masks\n",
    "    unique_keys = sorted(unique_masks_weights.keys())\n",
    "    unique_masks = [unique_masks_dict[key] for key in unique_keys]\n",
    "    summed_weights = [unique_masks_weights[key] for key in unique_keys]\n",
    "    mean_loss = [unique_masks_loss[key] for key in unique_keys]\n",
    "\n",
    "    return unique_masks, summed_weights, mean_loss #, mean_poolers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adebae7f-9e8c-4c0e-8694-eaa278ea3d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "unique_bool_masks, summed_weights, mean_loss = sum_weights_for_unique_masks(entry['unique_masks_used'], \n",
    "                                                                       entry[\"unique_mask_weights_used\"], \n",
    "                                                                       entry[\"unique_losses_used\"])\n",
    "\n",
    "for j in range(len(unique_bool_masks)):\n",
    "    weight_show = [round(val.item(), 4) for val in summed_weights[j]]\n",
    "    loss_show = [round(val.item(), 4) for val in mean_loss[j]]\n",
    "    label_show = [round(val.item(), 4) for val in entry[\"label\"]]\n",
    "    title = f'Weight: {weight_show}\\nLoss: {loss_show}\\n{label_show}'\n",
    "    map_plotter(entry['image'][0].cpu(), unique_bool_masks[j].cpu().numpy(), type='dim')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00723b20-9bc3-4fa3-a889-50252654861d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "277fed30-9eb5-4f0b-878a-99f0eff4bd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 664.67 GiB (GPU 0; 47.54 GiB total capacity; 1.68 GiB already allocated; 4.89 GiB free; 42.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17355/4039832198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m outputs_avg, outputs, attn_weights1, attn_weights2, pooler_outputs = model(inputs, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                            \u001b[0msegs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                            \u001b[0mmask_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                            return_tuple=True)\n\u001b[1;32m      5\u001b[0m \u001b[0moriginal_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackbone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/cosmogrid/../../lib/exlib/src/exlib/modules/sop.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, segs, input_mask_weights, epoch, mask_batch_size, label, return_tuple)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# Mask (Group) generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_mask_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0mgrouped_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mgrouped_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_mask_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# directly apply mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared_data0/weiqiuy/sop/notebooks/cosmogrid/../../lib/exlib/src/exlib/modules/sop.py\u001b[0m in \u001b[0;36mgroup_generate\u001b[0;34m(self, inputs, epoch, mask_batch_size, segs)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0msegment_mask_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_mask_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_segs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mnew_masks\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msegs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msegment_mask_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m             \u001b[0;31m# (bsz, num_new_masks, num_masks, img_dim1, img_dim2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0minput_mask_weights_cand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# if one mask has it, then have it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 664.67 GiB (GPU 0; 47.54 GiB total capacity; 1.68 GiB already allocated; 4.89 GiB free; 42.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs_avg, outputs, attn_weights1, attn_weights2, pooler_outputs = model(inputs, \n",
    "                                                                           segs=masks,\n",
    "                                                                           mask_batch_size=mask_batch_size, \n",
    "                                                                           return_tuple=True)\n",
    "original_outputs = backbone_model(inputs).logits\n",
    "\n",
    "preds_wrapped.append(outputs_avg)\n",
    "preds_original.append(original_outputs)\n",
    "gold_labels.append(labels)\n",
    "\n",
    "bsz, num_masks, num_labels = outputs.shape\n",
    "\n",
    "loss_avg = criterion(outputs_avg, labels)\n",
    "total_loss_wrapped += loss_avg.sum(0)\n",
    "loss_original = criterion(original_outputs, labels)\n",
    "total_loss_original += loss_original.sum(0)\n",
    "total_count += labels.size(0)\n",
    "loss = criterion(outputs.reshape(-1, model.config.num_labels), \n",
    "                 labels.unsqueeze(1).expand(bsz, \n",
    "                                            num_masks, \n",
    "                                            num_labels).reshape(-1, num_labels))\n",
    "loss = loss.reshape(outputs.shape)\n",
    "\n",
    "i = 0\n",
    "masks_used = attn_weights1[i][attn_weights2[i].sum(-1).bool()]  # get masks that are used for any class\n",
    "mask_weights = attn_weights2[i][attn_weights2[i].sum(-1).bool()]\n",
    "output_used = outputs[i][attn_weights2[i].sum(-1).bool()]\n",
    "pooler_used = pooler_outputs[i][attn_weights2[i].sum(-1).bool()]\n",
    "loss_used = loss[i][attn_weights2[i].sum(-1).bool()]\n",
    "\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "unique_masks_used, reverse_indices, counts = torch.unique(masks_used, \n",
    "                                                        dim=0, \n",
    "                                                        return_inverse=True, \n",
    "                                                        return_counts=True)\n",
    "indices = []\n",
    "reverse_indices = reverse_indices.cpu().numpy().tolist()\n",
    "\n",
    "for j in range(len(counts)):\n",
    "    indices.append(reverse_indices.index(j))\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "unique_mask_weights = mask_weights[indices] * counts.view(-1, 1)\n",
    "unique_outputs = output_used[indices]\n",
    "unique_preds = loss_used[indices].tolist()\n",
    "unique_pooler = pooler_used[indices]\n",
    "\n",
    "entry = {'image': images[i],\n",
    "        'outputs_avg': outputs_avg[i],\n",
    "        'outputs': unique_outputs, # outputs[i]\n",
    "        'pooler': unique_pooler,\n",
    "        'outputs_original': original_outputs[i],\n",
    "        'masks': attn_weights1[i].cpu().numpy(),\n",
    "        'masks_all': masks_i[i].cpu().numpy() \\\n",
    "            if masks_i is not None \\\n",
    "                else None,\n",
    "        'masks_used': unique_masks_used,  # masks_used,\n",
    "        'mask_weights': unique_mask_weights,  # mask_weights,\n",
    "        'pred': loss_avg[i].tolist(),\n",
    "        'preds': unique_preds, # predicted_raw[i].tolist(),\n",
    "        'label': labels[i].tolist(),\n",
    "        'counts': counts.cpu().numpy(),\n",
    "        'num_labels': model.config.num_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cdb9c-e35f-49a1-b421-208e6589d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "all_results = []\n",
    "\n",
    "progress_bar = tqdm(range(len(val_dataloader)))\n",
    "model.eval()\n",
    "preds_wrapped = []\n",
    "preds_original = []\n",
    "gold_labels = []\n",
    "with torch.no_grad():\n",
    "    idx = 0\n",
    "    total_loss_wrapped = 0\n",
    "    total_loss_original = 0\n",
    "    total_count = 0\n",
    "    for batch in val_loader:\n",
    "        output_filename = os.path.join(output_dirname, f'{idx}.pt')\n",
    "        if os.path.exists(output_filename):\n",
    "            progress_bar.update(1)\n",
    "            idx += 1\n",
    "            continue\n",
    "        inputs, labels, masks, masks_i = batch\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        images = inputs.cpu().numpy()\n",
    "\n",
    "        # images = [Image.fromarray(inputs_numpy[i]) for i in range(inputs_numpy.shape[0])]\n",
    "\n",
    "        outputs_avg, outputs, attn_weights1, attn_weights2, pooler_outputs = model(inputs, \n",
    "                                                                   masks=masks,\n",
    "                                epoch=model.config.num_heads,\n",
    "                                mask_batch_size=args.mask_batch_size,\n",
    "                                return_pooler=True)\n",
    "        original_outputs = backbone_model(inputs).logits\n",
    "\n",
    "        preds_wrapped.append(outputs_avg)\n",
    "        preds_original.append(original_outputs)\n",
    "        gold_labels.append(labels)\n",
    "\n",
    "        bsz, num_masks, num_labels = outputs.shape\n",
    "\n",
    "        loss_avg = criterion(outputs_avg, labels)\n",
    "        total_loss_wrapped += loss_avg.sum(0)\n",
    "        loss_original = criterion(original_outputs, labels)\n",
    "        total_loss_original += loss_original.sum(0)\n",
    "        total_count += labels.size(0)\n",
    "        loss = criterion(outputs.reshape(-1, model.config.num_labels), \n",
    "                         labels.unsqueeze(1).expand(bsz, \n",
    "                                                    num_masks, \n",
    "                                                    num_labels).reshape(-1, num_labels))\n",
    "        loss = loss.reshape(outputs.shape)\n",
    "\n",
    "        if not args.scatter_only:\n",
    "            for i in range(len(images)):\n",
    "\n",
    "                masks_used = attn_weights1[i][attn_weights2[i].sum(-1).bool()]  # get masks that are used for any class\n",
    "                mask_weights = attn_weights2[i][attn_weights2[i].sum(-1).bool()]\n",
    "                output_used = outputs[i][attn_weights2[i].sum(-1).bool()]\n",
    "                pooler_used = pooler_outputs[i][attn_weights2[i].sum(-1).bool()]\n",
    "                loss_used = loss[i][attn_weights2[i].sum(-1).bool()]\n",
    "\n",
    "                # import pdb\n",
    "                # pdb.set_trace()\n",
    "                unique_masks_used, reverse_indices, counts = torch.unique(masks_used, \n",
    "                                                                        dim=0, \n",
    "                                                                        return_inverse=True, \n",
    "                                                                        return_counts=True)\n",
    "                indices = []\n",
    "                reverse_indices = reverse_indices.cpu().numpy().tolist()\n",
    "\n",
    "                for j in range(len(counts)):\n",
    "                    indices.append(reverse_indices.index(j))\n",
    "                # import pdb\n",
    "                # pdb.set_trace()\n",
    "                unique_mask_weights = mask_weights[indices] * counts.view(-1, 1)\n",
    "                unique_outputs = output_used[indices]\n",
    "                unique_preds = loss_used[indices].tolist()\n",
    "                unique_pooler = pooler_used[indices]\n",
    "\n",
    "                entry = {'image': images[i],\n",
    "                        'outputs_avg': outputs_avg[i],\n",
    "                        'outputs': unique_outputs, # outputs[i]\n",
    "                        'pooler': unique_pooler,\n",
    "                        'outputs_original': original_outputs[i],\n",
    "                        'masks': attn_weights1[i].cpu().numpy(),\n",
    "                        'masks_all': masks_i[i].cpu().numpy() \\\n",
    "                            if masks_i is not None \\\n",
    "                                else None,\n",
    "                        'masks_used': unique_masks_used,  # masks_used,\n",
    "                        'mask_weights': unique_mask_weights,  # mask_weights,\n",
    "                        'pred': loss_avg[i].tolist(),\n",
    "                        'preds': unique_preds, # predicted_raw[i].tolist(),\n",
    "                        'label': labels[i].tolist(),\n",
    "                        'counts': counts.cpu().numpy(),\n",
    "                        'num_labels': model.config.num_labels}\n",
    "\n",
    "                # print('attn_weights1[i]', attn_weights1[i].shape)\n",
    "                # print('attn_weights2[i]', attn_weights2[i].shape)\n",
    "\n",
    "                all_results.append(entry)\n",
    "                output_filename = os.path.join(output_dirname, f'{idx}.pkl')\n",
    "                torch.save(entry, output_filename)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        idx += 1\n",
    "\n",
    "        del images\n",
    "\n",
    "    preds_wrapped = torch.cat(preds_wrapped).cpu().numpy()\n",
    "    preds_original = torch.cat(preds_original).cpu().numpy()\n",
    "    gold_labels = torch.cat(gold_labels).cpu().numpy()\n",
    "\n",
    "    plot_y = gold_labels\n",
    "    # predictions = preds\n",
    "    upp_lims = np.nanmax(plot_y, axis=0)\n",
    "    low_lims = np.nanmin(plot_y, axis=0)\n",
    "\n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(low_lims), figsize=(20, 10))\n",
    "\n",
    "    for ind, (low_lim, upp_lim) in enumerate(zip(low_lims, upp_lims)):\n",
    "        p_w = np.poly1d(np.polyfit(plot_y[:, ind], preds_wrapped[:, ind], 1))\n",
    "        p_o = np.poly1d(np.polyfit(plot_y[:, ind], preds_original[:, ind], 1))\n",
    "\n",
    "        axes[ind].scatter(plot_y[:, ind], preds_wrapped[:, ind], color=\"blue\", label='Wrapped')\n",
    "        axes[ind].scatter(plot_y[:, ind], preds_original[:, ind], color=\"orange\", label='Original')\n",
    "        axes[ind].plot([low_lim, upp_lim], [low_lim, upp_lim], color=\"black\")\n",
    "        axes[ind].plot([low_lim, upp_lim], [p_w(low_lim), p_w(upp_lim)], color=\"black\", ls=\":\", label='Wrapped')\n",
    "        axes[ind].plot([low_lim, upp_lim], [p_o(low_lim), p_o(upp_lim)], color=\"black\", ls=\"-.\", label='Original')\n",
    "        axes[ind].set_xlim([low_lim, upp_lim])\n",
    "        axes[ind].set_ylim([low_lim, upp_lim])\n",
    "        axes[ind].set_xlabel('Gold')\n",
    "        axes[ind].set_ylabel('Pred')\n",
    "        axes[ind].legend()\n",
    "        axes[ind].set_aspect('equal', adjustable='box')\n",
    "\n",
    "        original_loss = round((total_loss_original / total_count)[ind].cpu().item(), 4)\n",
    "        wrapped_loss = round((total_loss_wrapped / total_count)[ind].cpu().item(), 4)\n",
    "\n",
    "        axes[ind].set_title(f'Output {ind}, \\n' + \n",
    "                            f'Original loss {original_loss},\\n' +\n",
    "                            f'Wrapped loss {wrapped_loss}')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.9)\n",
    "    plt.savefig(os.path.join(args.exp_dir, 'combined_scatter.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(low_lims), figsize=(20, 10))\n",
    "\n",
    "    for ind, (low_lim, upp_lim) in enumerate(zip(low_lims, upp_lims)):\n",
    "        p_w = np.poly1d(np.polyfit(plot_y[:, ind], preds_wrapped[:, ind], 1))\n",
    "        p_o = np.poly1d(np.polyfit(plot_y[:, ind], preds_original[:, ind], 1))\n",
    "\n",
    "        # (Wrapped - Gold) / Gold\n",
    "        diff_wrapped = (preds_wrapped[:, ind] - plot_y[:, ind]) / plot_y[:, ind]\n",
    "        # (Original - Gold) / Gold\n",
    "        diff_original = (preds_original[:, ind] - plot_y[:, ind]) / plot_y[:, ind]\n",
    "        axes[ind].scatter(plot_y[:, ind], diff_wrapped, color=\"green\", label='Wrapped')\n",
    "        axes[ind].scatter(plot_y[:, ind], diff_original, color=\"red\", label='Original')\n",
    "        axes[ind].scatter(plot_y[:, ind], preds_wrapped[:, ind], color=\"blue\", label='Wrapped')\n",
    "        axes[ind].scatter(plot_y[:, ind], preds_original[:, ind], color=\"orange\", label='Original')\n",
    "        axes[ind].plot([low_lim, upp_lim], [low_lim, upp_lim], color=\"black\")\n",
    "        axes[ind].plot([low_lim, upp_lim], [p_w(low_lim), p_w(upp_lim)], color=\"black\", ls=\":\", label='Wrapped')\n",
    "        axes[ind].plot([low_lim, upp_lim], [p_o(low_lim), p_o(upp_lim)], color=\"black\", ls=\"-.\", label='Original')\n",
    "        # axes[ind].set_xlim([low_lim, upp_lim])\n",
    "        # axes[ind].set_ylim([low_lim, upp_lim])\n",
    "        axes[ind].set_xlabel('Gold')\n",
    "        axes[ind].set_ylabel('Pred')\n",
    "        axes[ind].legend()\n",
    "        axes[ind].set_aspect('equal', adjustable='box')\n",
    "\n",
    "        original_loss = round((total_loss_original / total_count)[ind].cpu().item(), 4)\n",
    "        wrapped_loss = round((total_loss_wrapped / total_count)[ind].cpu().item(), 4)\n",
    "\n",
    "        axes[ind].set_title(f'Output {ind}, \\n' + \n",
    "                            f'Original loss {original_loss},\\n' +\n",
    "                            f'Wrapped loss {wrapped_loss}')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.9)\n",
    "    plt.savefig(os.path.join(args.exp_dir, 'combined_scatter_diff.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(low_lims), figsize=(20, 10))\n",
    "\n",
    "\n",
    "    for ind, (low_lim, upp_lim) in enumerate(zip(low_lims, upp_lims)):\n",
    "        p_w = np.poly1d(np.polyfit(plot_y[:, ind], preds_wrapped[:, ind], 1))\n",
    "        p_o = np.poly1d(np.polyfit(plot_y[:, ind], preds_original[:, ind], 1))\n",
    "\n",
    "        # (Wrapped - Gold) / Gold\n",
    "        diff_wrapped = (preds_wrapped[:, ind] - plot_y[:, ind]) / plot_y[:, ind]\n",
    "        # (Original - Gold) / Gold\n",
    "        diff_original = (preds_original[:, ind] - plot_y[:, ind]) / plot_y[:, ind]\n",
    "        axes[ind].scatter(plot_y[:, ind], diff_wrapped, color=\"blue\", label='Wrapped')\n",
    "        axes[ind].scatter(plot_y[:, ind], diff_original, color=\"orange\", label='Original')\n",
    "        # axes[ind].plot([low_lim, upp_lim], [low_lim, upp_lim], color=\"black\")\n",
    "        # axes[ind].plot([low_lim, upp_lim], [p_w(low_lim), p_w(upp_lim)], color=\"black\", ls=\":\", label='Wrapped')\n",
    "        # axes[ind].plot([low_lim, upp_lim], [p_o(low_lim), p_o(upp_lim)], color=\"black\", ls=\"-.\", label='Original')\n",
    "        # axes[ind].set_xlim([low_lim, upp_lim])\n",
    "        # axes[ind].set_ylim([low_lim, upp_lim])\n",
    "        axes[ind].set_xlabel('Gold')\n",
    "        axes[ind].set_ylabel('Pred')\n",
    "        axes[ind].legend()\n",
    "        axes[ind].set_aspect('equal', adjustable='box')\n",
    "\n",
    "        original_loss = round((total_loss_original / total_count)[ind].cpu().item(), 4)\n",
    "        wrapped_loss = round((total_loss_wrapped / total_count)[ind].cpu().item(), 4)\n",
    "\n",
    "        axes[ind].set_title(f'Output {ind}, \\n' + \n",
    "                            f'Original loss {original_loss},\\n' +\n",
    "                            f'Wrapped loss {wrapped_loss}')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.9)\n",
    "    plt.savefig(os.path.join(args.exp_dir, 'combined_scatter_diff_only.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print('mean-center-offset', args.mean_center_offset)\n",
    "    print('mean-center-scale', args.mean_center_scale)\n",
    "    print('mean-center-offset2', args.mean_center_offset2)\n",
    "    print('mean-center-scale2', args.mean_center_scale2)\n",
    "    print('original_loss', original_loss)\n",
    "    print('wrapped_loss', wrapped_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
