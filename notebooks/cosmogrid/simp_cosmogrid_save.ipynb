{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4ecc05-506f-4f2b-93e5-563060c9f672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_weights_for_unique_masks(masks, masks_weights, logits): #, poolers):\n",
    "    # Convert each boolean mask to a unique string of 0s and 1s\n",
    "    mask_strs = [''.join(map(str, mask.bool().int().flatten().tolist())) for mask in masks]\n",
    "    img_size = 66\n",
    "\n",
    "    # Dictionary to store summed weights for each unique mask\n",
    "    unique_masks_weights = {}\n",
    "    unique_masks_logits = {}\n",
    "    unique_masks_count = {}\n",
    "    unique_masks_dict = {}\n",
    "\n",
    "    for i, (mask_str, weight, pred) in enumerate(zip(mask_strs, masks_weights, logits)):\n",
    "        if mask_str in unique_masks_weights:\n",
    "            unique_masks_weights[mask_str] += weight\n",
    "            unique_masks_logits[mask_str] += pred\n",
    "            unique_masks_count[mask_str] += 1\n",
    "        else:\n",
    "            unique_masks_dict[mask_str] = masks[i]\n",
    "            unique_masks_weights[mask_str] = weight\n",
    "            unique_masks_logits[mask_str] = pred\n",
    "            unique_masks_count[mask_str] = 1\n",
    "\n",
    "    # Convert dictionary keys back to boolean masks\n",
    "    unique_keys = sorted(unique_masks_weights.keys())\n",
    "    unique_masks = [unique_masks_dict[key] for key in unique_keys]\n",
    "    summed_weights = [unique_masks_weights[key] for key in unique_keys]\n",
    "    mean_logits = [unique_masks_logits[key] for key in unique_keys]\n",
    "\n",
    "    return unique_masks, summed_weights, mean_logits #, mean_poolers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81b8efc-fdc9-463d-8d8c-a24fec645538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500c7176afab4a4fb118fff336c28b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_155/232177286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moriginal_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbyte\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mread_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "input_dir = '../../exps/cosmogrid_4h/best/val_results'\n",
    "output_dir = '../../exps/cosmogrid_4h/best/val_results_simp'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "X = []\n",
    "images = []\n",
    "mask_paths = []\n",
    "mask_idxs = []\n",
    "preds_all = []\n",
    "labels_all = []\n",
    "mask_id_feat_dict = {}\n",
    "\n",
    "\n",
    "count = 0\n",
    "filenames = sorted(os.listdir(input_dir))\n",
    "stats_all = []\n",
    "total = 0\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    if os.path.exists(os.path.join(output_dir, filename)):\n",
    "        continue\n",
    "    data = torch.load(os.path.join(input_dir, filename))\n",
    "    image = data['image']\n",
    "    original_logits = data['original_logits']\n",
    "    logits = data['logits']\n",
    "    unique_logits_used = data['unique_logits_used']\n",
    "    masks = data['masks']\n",
    "    unique_masks_used = data['unique_masks_used']\n",
    "    unique_mask_weights_used = data['unique_mask_weights_used']\n",
    "    unique_losses_used = data['unique_losses_used']\n",
    "    label = data['label']\n",
    "    counts = data['counts']\n",
    "    num_labels = data['num_labels']\n",
    "    \n",
    "    unique_masks, summed_weights, mean_logits = sum_weights_for_unique_masks(unique_masks_used, \n",
    "                                                                        unique_mask_weights_used, \n",
    "                                                                        unique_logits_used)\n",
    "    \n",
    "    new_res = {\n",
    "        'image': image,\n",
    "        'label': label,\n",
    "        'logits': logits,\n",
    "        'unique_masks': unique_masks,\n",
    "        'summed_weights': summed_weights,\n",
    "        'mean_logits': mean_logits\n",
    "    }\n",
    "    \n",
    "    torch.save(new_res, os.path.join(output_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8657b9-b89e-4912-a698-9b514c739c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
